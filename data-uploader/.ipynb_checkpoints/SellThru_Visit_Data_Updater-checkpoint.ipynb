{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from pytz import timezone\n",
    "\n",
    "import json\n",
    "from geojson import Feature, FeatureCollection, Point\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing Last 20wk sell-thru data and creating sell-thru dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_thru_df = pd.read_csv('Resources/for_sell_thru_update/sell_thru_data_to_be_updated_manually.csv') \n",
    "sell_thru_df = sell_thru_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding columns\n",
    "sell_thru_df = sell_thru_df.rename(columns={'Store#': 'Location_Number'})\n",
    "\n",
    "sell_thru_df[\"Last_Week_ST\"] = sell_thru_df[\"Wk_1\"]\n",
    "sell_thru_df[\"Last_5wk_Ave_ST\"] = (sell_thru_df[\"Wk_1\"] + sell_thru_df[\"Wk_2\"] + sell_thru_df[\"Wk_3\"] + sell_thru_df[\"Wk_4\"] + sell_thru_df[\"Wk_5\"]) / 5\n",
    "sell_thru_df[\"Last_10wk_Ave_ST\"] = (sell_thru_df[\"Wk_1\"] + sell_thru_df[\"Wk_2\"] + sell_thru_df[\"Wk_3\"] + sell_thru_df[\"Wk_4\"] + sell_thru_df[\"Wk_5\"] + sell_thru_df[\"Wk_6\"] + sell_thru_df[\"Wk_7\"] + sell_thru_df[\"Wk_8\"] + sell_thru_df[\"Wk_9\"] + sell_thru_df[\"Wk_10\"]) / 10\n",
    "sell_thru_df[\"Last_20wk_Ave_ST\"] = (sell_thru_df[\"Wk_1\"] + sell_thru_df[\"Wk_2\"] + sell_thru_df[\"Wk_3\"] + sell_thru_df[\"Wk_4\"] + sell_thru_df[\"Wk_5\"] + sell_thru_df[\"Wk_6\"] + sell_thru_df[\"Wk_7\"] + sell_thru_df[\"Wk_8\"] + sell_thru_df[\"Wk_9\"] + sell_thru_df[\"Wk_10\"] + sell_thru_df[\"Wk_11\"] + sell_thru_df[\"Wk_12\"] + sell_thru_df[\"Wk_13\"] + sell_thru_df[\"Wk_14\"] + sell_thru_df[\"Wk_15\"] + sell_thru_df[\"Wk_16\"] + sell_thru_df[\"Wk_17\"] + sell_thru_df[\"Wk_18\"] + sell_thru_df[\"Wk_19\"] + sell_thru_df[\"Wk_20\"]) / 20\n",
    "\n",
    "Last_Week_Total = sell_thru_df['Last_Week_ST'].sum()\n",
    "Last_5Wk_Ave_Total = sell_thru_df['Last_5wk_Ave_ST'].sum()\n",
    "Last_10Wk_Ave_Total = sell_thru_df['Last_10wk_Ave_ST'].sum()\n",
    "Last_20Wk_Ave_Total = sell_thru_df['Last_20wk_Ave_ST'].sum()\n",
    "\n",
    "sell_thru_df[\"Last_Week_Share\"] = sell_thru_df[\"Last_Week_ST\"] / Last_Week_Total * 100\n",
    "sell_thru_df[\"Last_5Wk_Share\"] = sell_thru_df[\"Last_5wk_Ave_ST\"] / Last_5Wk_Ave_Total * 100\n",
    "sell_thru_df[\"Last_10Wk_Share\"] = sell_thru_df[\"Last_10wk_Ave_ST\"] / Last_10Wk_Ave_Total * 100\n",
    "sell_thru_df[\"Last_20Wk_Share\"] = sell_thru_df[\"Last_20wk_Ave_ST\"] / Last_20Wk_Ave_Total * 100\n",
    "\n",
    "sell_thru_df[\"Last_5wk_Performance\"] = sell_thru_df[\"Last_5Wk_Share\"] / sell_thru_df[\"Last_20Wk_Share\"] * 100\n",
    "sell_thru_df = sell_thru_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making time format\n",
    "year_format = \"%Y\"\n",
    "\n",
    "# Getting the current date & time\n",
    "now_pst = datetime.now(timezone('US/Pacific'))\n",
    "now_pst_last_week = now_pst - dt.timedelta(days=7)\n",
    "tomorrow_pst = now_pst + dt.timedelta(days=1)\n",
    "tomorrow_pst_last_week = tomorrow_pst - dt.timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ISO weeknumber and convert the format\n",
    "week_data = tomorrow_pst_last_week.isocalendar()[1]\n",
    "year_data = now_pst_last_week.strftime(year_format)\n",
    "\n",
    "if week_data < 10 :\n",
    "    last_week = year_data + \"w\" + \"0\" + str(week_data)\n",
    "else: \n",
    "    last_week = year_data + \"w\" + str(week_data)\n",
    "    \n",
    "last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_thru_df[\"Last_Wk\"] = last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_thru_df = sell_thru_df[['Location_Number', 'Last_Week_ST', 'Last_5wk_Ave_ST', 'Last_10wk_Ave_ST', 'Last_20wk_Ave_ST', 'Last_Week_Share', 'Last_5Wk_Share', 'Last_10Wk_Share', 'Last_20Wk_Share', 'Last_5wk_Performance', 'Last_Wk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round the numbers in sell_thru_df\n",
    "sell_thru_df = sell_thru_df.round({'Last_Week_ST': 0, 'Last_5wk_Ave_ST': 1, 'Last_10wk_Ave_ST': 1, 'Last_20wk_Ave_ST': 1, 'Last_Week_Share': 3, 'Last_5Wk_Share': 3, 'Last_10Wk_Share': 3, 'Last_20Wk_Share': 3, 'Last_5wk_Performance': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting \"Last_Week_ST\" and \"Last_5wk_Performance\" into Integer\n",
    "sell_thru_df.Last_Week_ST = sell_thru_df.Last_Week_ST.astype(int)\n",
    "sell_thru_df.Last_5wk_Performance = sell_thru_df.Last_5wk_Performance.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_thru_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing Premium 10wk sell-thru data and adding it to sell-thru dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premium_sell_thru_df = pd.read_csv('Resources/for_sell_thru_update/premium_sell_thru_data_to_be_updated_manually.csv') \n",
    "premium_sell_thru_df = premium_sell_thru_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adding columns\n",
    "premium_sell_thru_df = premium_sell_thru_df.rename(columns={'Store#': 'Location_Number'})\n",
    "\n",
    "premium_sell_thru_df[\"Premium_Last_10wk_Ave_ST\"] = (premium_sell_thru_df[\"Wk_1\"] + premium_sell_thru_df[\"Wk_2\"] + premium_sell_thru_df[\"Wk_3\"] + premium_sell_thru_df[\"Wk_4\"] + premium_sell_thru_df[\"Wk_5\"] + premium_sell_thru_df[\"Wk_6\"] + premium_sell_thru_df[\"Wk_7\"] + premium_sell_thru_df[\"Wk_8\"] + premium_sell_thru_df[\"Wk_9\"] + premium_sell_thru_df[\"Wk_10\"]) / 10\n",
    "\n",
    "premium_10wk_total = premium_sell_thru_df[\"Premium_Last_10wk_Ave_ST\"].sum()\n",
    "\n",
    "premium_sell_thru_df[\"Premium_10wk_Share\"] = premium_sell_thru_df[\"Premium_Last_10wk_Ave_ST\"] / premium_10wk_total * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting only Location_Number, Last_10wk_AveST and Share\n",
    "premium_sell_thru_df = premium_sell_thru_df[['Location_Number', 'Premium_Last_10wk_Ave_ST', 'Premium_10wk_Share']]\n",
    "premium_sell_thru_df = premium_sell_thru_df.round({'Premium_Last_10wk_Ave_ST': 2, 'Premium_10wk_Share': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data type of Location_Number to str\n",
    "premium_sell_thru_df.Location_Number = premium_sell_thru_df.Location_Number.astype(str)\n",
    "sell_thru_df.Location_Number = sell_thru_df.Location_Number.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_thru_df = sell_thru_df.merge(premium_sell_thru_df, on='Location_Number', how='left')\n",
    "sell_thru_df = sell_thru_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_thru_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing Best Buy Geo Store List (Geo Data needs to be updated separately once Master Store List is updated )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Store List with Geo Data\n",
    "BBY_Store_List_GeoData_df = pd.read_csv('Resources/for_store_list_update/BestBuy_Store_List_GeoData.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting Location_Number to String\n",
    "BBY_Store_List_GeoData_df.Location_Number = BBY_Store_List_GeoData_df.Location_Number.astype(str)\n",
    "sell_thru_df.Location_Number = sell_thru_df.Location_Number.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left Merge the df\n",
    "BBY_Store_List_GeoData_Sell_thru_df = BBY_Store_List_GeoData_df.merge(sell_thru_df, on='Location_Number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBY_Store_List_GeoData_Sell_thru_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting Store visit information from Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1st report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('***Confidential', scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_gio = gc.open('US Field Team Report 2018').get_worksheet(0)\n",
    "record_gio = worksheet_gio.get_all_records()\n",
    "df_gio = pd.DataFrame(data=record_gio)\n",
    "df_gio = df_gio[['Store#/Name', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_gio = df_gio.rename(columns={'Store#/Name': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'                                \n",
    "                                })\n",
    "\n",
    "for index, row in df_gio.iterrows():\n",
    "    df_gio.at[index, \"Location_Number\"] = str(df_gio.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_felix = gc.open('US Field Team Report 2018').get_worksheet(1)\n",
    "record_felix = worksheet_felix.get_all_records()\n",
    "df_felix = pd.DataFrame(data=record_felix)\n",
    "df_felix = df_felix[['Store#/Name', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_felix = df_felix.rename(columns={'Store#/Name': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_felix.iterrows():\n",
    "    df_felix.at[index, \"Location_Number\"] = str(df_felix.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_freddie = gc.open('US Field Team Report 2018').get_worksheet(2)\n",
    "record_freddie = worksheet_freddie.get_all_records()\n",
    "df_freddie = pd.DataFrame(data=record_freddie)\n",
    "df_freddie = df_freddie[['Store#/Name', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_freddie = df_freddie.rename(columns={'Store#/Name': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_freddie.iterrows():\n",
    "    df_freddie.at[index, \"Location_Number\"] = str(df_freddie.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_khoa = gc.open('US Field Team Report 2018').get_worksheet(3)\n",
    "record_khoa = worksheet_khoa.get_all_records()\n",
    "df_khoa = pd.DataFrame(data=record_khoa)\n",
    "df_khoa = df_khoa[['Store#/Name', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_khoa = df_khoa.rename(columns={'Store#/Name': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_khoa.iterrows():\n",
    "    df_khoa.at[index, \"Location_Number\"] = str(df_khoa.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_maggie = gc.open('US Field Team Report 2018').get_worksheet(4)\n",
    "record_maggie = worksheet_maggie.get_all_records()\n",
    "df_maggie = pd.DataFrame(data=record_maggie)\n",
    "df_maggie = df_maggie[['Store#/Name', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_maggie = df_maggie.rename(columns={'Store#/Name': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_maggie.iterrows():\n",
    "    df_maggie.at[index, \"Location_Number\"] = str(df_maggie.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_jon = gc.open('US Field Team Report 2018').get_worksheet(5)\n",
    "record_jon = worksheet_jon.get_all_records()\n",
    "df_jon = pd.DataFrame(data=record_jon)\n",
    "df_jon = df_jon[['Store#/Name', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_jon = df_jon.rename(columns={'Store#/Name': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_jon.iterrows():\n",
    "    df_jon.at[index, \"Location_Number\"] = str(df_jon.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_gio_2 = gc.open('US_Field_Team_Report_2019_Feb-').get_worksheet(0)\n",
    "record_gio_2 = worksheet_gio_2.get_all_records()\n",
    "df_gio_2 = pd.DataFrame(data=record_gio_2)\n",
    "df_gio_2 = df_gio_2[['Store#', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_gio_2 = df_gio_2.rename(columns={'Store#': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'                                \n",
    "                                })\n",
    "\n",
    "for index, row in df_gio_2.iterrows():\n",
    "    df_gio_2.at[index, \"Location_Number\"] = str(df_gio_2.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_felix_2 = gc.open('US_Field_Team_Report_2019_Feb-').get_worksheet(1)\n",
    "record_felix_2 = worksheet_felix_2.get_all_records()\n",
    "df_felix_2 = pd.DataFrame(data=record_felix_2)\n",
    "df_felix_2 = df_felix_2[['Store#', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_felix_2 = df_felix_2.rename(columns={'Store#': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_felix_2.iterrows():\n",
    "    df_felix_2.at[index, \"Location_Number\"] = str(df_felix_2.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_freddie_2 = gc.open('US_Field_Team_Report_2019_Feb-').get_worksheet(2)\n",
    "record_freddie_2 = worksheet_freddie_2.get_all_records()\n",
    "df_freddie_2 = pd.DataFrame(data=record_freddie_2)\n",
    "df_freddie_2 = df_freddie_2[['Store#', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_freddie_2 = df_freddie_2.rename(columns={'Store#': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_freddie_2.iterrows():\n",
    "    df_freddie_2.at[index, \"Location_Number\"] = str(df_freddie_2.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_khoa_2 = gc.open('US_Field_Team_Report_2019_Feb-').get_worksheet(3)\n",
    "record_khoa_2 = worksheet_khoa_2.get_all_records()\n",
    "df_khoa_2 = pd.DataFrame(data=record_khoa_2)\n",
    "df_khoa_2 = df_khoa_2[['Store#', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_khoa_2 = df_khoa_2.rename(columns={'Store#': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_khoa_2.iterrows():\n",
    "    df_khoa_2.at[index, \"Location_Number\"] = str(df_khoa_2.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_maggie_2 = gc.open('US_Field_Team_Report_2019_Feb-').get_worksheet(4)\n",
    "record_maggie_2 = worksheet_maggie_2.get_all_records()\n",
    "df_maggie_2 = pd.DataFrame(data=record_maggie_2)\n",
    "df_maggie_2 = df_maggie_2[['Store#', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_maggie_2 = df_maggie_2.rename(columns={'Store#': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_maggie_2.iterrows():\n",
    "    df_maggie_2.at[index, \"Location_Number\"] = str(df_maggie_2.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_jon_2 = gc.open('US_Field_Team_Report_2019_Feb-').get_worksheet(5)\n",
    "record_jon_2 = worksheet_jon_2.get_all_records()\n",
    "df_jon_2 = pd.DataFrame(data=record_jon_2)\n",
    "df_jon_2 = df_jon_2[['Store#', 'Visit Date', 'Who visited', 'Status(P/C)', 'Photo 1', 'Photo 2', 'Photo 3', 'Photo 4', 'Photo 5', 'Key Findings / Pending issues / Status update', 'Memo']]\n",
    "df_jon_2 = df_jon_2.rename(columns={'Store#': 'Location_Number', \n",
    "                                'Visit Date': 'Last_Visit',\n",
    "                                'Who visited': 'Who_Visited',\n",
    "                                'Status(P/C)': 'Status',\n",
    "                                'Photo 1': 'Photo_1',\n",
    "                                'Photo 2': 'Photo_2',\n",
    "                                'Photo 3': 'Photo_3',\n",
    "                                'Photo 4': 'Photo_4',\n",
    "                                'Photo 5': 'Photo_5',\n",
    "                                'Key Findings / Pending issues / Status update': 'Comment',\n",
    "                                'Memo': 'Memo'  \n",
    "                                })\n",
    "\n",
    "for index, row in df_jon_2.iterrows():\n",
    "    df_jon_2.at[index, \"Location_Number\"] = str(df_jon_2.at[index, \"Location_Number\"]).replace(\"B\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging each df\n",
    "frames = [df_gio, df_felix, df_freddie, df_khoa, df_maggie, df_jon, df_gio_2, df_felix_2, df_freddie_2, df_khoa_2, df_maggie_2, df_jon_2]\n",
    "merged_store_visit_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_store_visit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert date into datetime data type\n",
    "merged_store_visit_df['Last_Visit'] = pd.to_datetime(merged_store_visit_df.Last_Visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting by date (new to old)\n",
    "merged_store_visit_df = merged_store_visit_df.sort_values('Last_Visit', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting index\n",
    "merged_store_visit_df = merged_store_visit_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_store_visit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing \"memo\" in separate dictionary\n",
    "memo_dict = {}\n",
    "\n",
    "for index, row in merged_store_visit_df.iterrows():\n",
    "    if row['Memo'] != '':\n",
    "        if row['Location_Number'] not in list(memo_dict.keys()):\n",
    "            memo_dict[str(row['Location_Number'])] = str(row['Memo']) + \", \"\n",
    "        else:\n",
    "            memo_dict[str(row['Location_Number'])] += str(row['Memo']) + \", \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making memo_df\n",
    "memo_df = pd.DataFrame(list(memo_dict.items()), columns=['Location_Number', 'Memo'])\n",
    "memo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_store_visit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping \"Memo\" from merged_store_visit_df\n",
    "merged_store_visit_df = merged_store_visit_df.drop(columns=['Memo'])\n",
    "merged_store_visit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Picking up the latest visit (Replace Location_Number to \"Already_Counted\" if it is once counted.)\n",
    "store_list = []\n",
    "\n",
    "for index, row in merged_store_visit_df.iterrows():\n",
    "    if row['Location_Number'] in store_list:\n",
    "        merged_store_visit_df.at[index, 'Location_Number'] = \"Already_Counted\"\n",
    "    else:\n",
    "        store_list.append(row['Location_Number'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left merge 1 with Geo data\n",
    "BBY_Store_List_GeoData_Sell_thru_Store_visit_df = BBY_Store_List_GeoData_Sell_thru_df.merge(merged_store_visit_df, on='Location_Number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left merge 2 with Memo data\n",
    "BBY_Store_List_GeoData_Sell_thru_Store_visit_df = BBY_Store_List_GeoData_Sell_thru_Store_visit_df.merge(memo_df, on='Location_Number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBY_Store_List_GeoData_Sell_thru_Store_visit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBY_Store_List_GeoData_Sell_thru_Store_visit_df.to_csv('Resources/for_sell_thru_update/geodata_sell_thru_visit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating JSON file from the geodata_sell_thru_visit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Resources/for_sell_thru_update/geodata_sell_thru_visit.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "with open(file_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for latitude, longitude, location_number, location_name, address_1, address_2, city, state, zip_code, \\\n",
    "    telephone_nbr, current_endcap, current_table_display, t1_update, last_week_st, last_5wk_ave_st, last_10wk_ave_st, \\\n",
    "    last_20wk_ave_st, last_wk_share, last_5wk_share, last_10wk_share, last_20wk_share, last_5wk_performance, lastwknumber, premium_10wk, premium_10wk_share, \\\n",
    "    last_visit, who_visited, status, photo_1, photo_2, photo_3, photo_4, photo_5, comment, memo in reader:\n",
    "        latitude, longitude = map(float, (latitude, longitude))\n",
    "        features.append(\n",
    "            Feature(\n",
    "                geometry = Point((longitude, latitude)),\n",
    "                properties = {\n",
    "                    'storenumber': location_number,\n",
    "                    'storename': location_name,\n",
    "                    'address1': address_1,\n",
    "                    'address2': address_2,\n",
    "                    'city': city,\n",
    "                    'state': state,\n",
    "                    'zipcode': zip_code,\n",
    "                    'telephonenumber': telephone_nbr,\n",
    "                    'endcap': current_endcap,\n",
    "                    'tabledisplay': current_table_display,\n",
    "                    't1update': t1_update,\n",
    "                    'lastwkst': last_week_st,\n",
    "                    'last5wkavest': last_5wk_ave_st,\n",
    "                    'last10wkavest': last_10wk_ave_st,\n",
    "                    'last20wkavest': last_20wk_ave_st,\n",
    "                    'lastwkshare': last_wk_share,\n",
    "                    'last5wkshare': last_5wk_share,\n",
    "                    'last10wkshare': last_10wk_share,\n",
    "                    'last20wkshare': last_20wk_share,\n",
    "                    'last5wkperformance': last_5wk_performance,\n",
    "                    'lastwknumber': lastwknumber,\n",
    "                    'premium_10wk': premium_10wk,\n",
    "                    'premium_10wk_share': premium_10wk_share,\n",
    "                    'last_visit': last_visit,\n",
    "                    'who_visited': who_visited,\n",
    "                    'status': status,\n",
    "                    'photo_1': photo_1,\n",
    "                    'photo_2': photo_2,\n",
    "                    'photo_3': photo_3,\n",
    "                    'photo_4': photo_4,\n",
    "                    'photo_5': photo_5,                    \n",
    "                    'comment': comment,\n",
    "                    'memo': memo\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "collection = FeatureCollection(features)\n",
    "with open(\"Resources/GeoJson_Data_BBY.json\", \"w\") as f:\n",
    "    f.write('%s' % collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(collection[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting previous JSON file from AWS S3 and Uploading new JSON file to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID & Secret Key created on 12/21/2018 \n",
    "s3_id = '***Confidential'\n",
    "s3_secret = '***Confidential'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to AWS S3 and making an object of the previous JSON file\n",
    "bucket = \"***Confidential\"\n",
    "file_name = \"GeoJson_Data_BBY.json\"\n",
    "\n",
    "s3client = boto3.resource('s3', aws_access_key_id=s3_id, aws_secret_access_key=s3_secret)\n",
    "\n",
    "content_object = s3client.Object(bucket, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the previous JSON file from AWS S3 Bucket\n",
    "content_object.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding New JSON file to AWS S3 Bucket\n",
    "s3client.Object(bucket, file_name).upload_file(Filename='Resources/GeoJson_Data_BBY.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
